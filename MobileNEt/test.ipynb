{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'keras.src.layers.convolutional.conv2d.Conv2D'>\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "print(keras.layers.Conv2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "print()\n",
    "# Initialize the HOG descriptor/person detector\n",
    "hog = cv2.HOGDescriptor()\n",
    "hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
    "\n",
    "# Open input video file\n",
    "input_file = r'Videos\\vid.mp4'\n",
    "cap = cv2.VideoCapture(input_file)\n",
    "\n",
    "# Get video properties\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "# Output video file\n",
    "out = cv2.VideoWriter(\n",
    "    'output.avi',\n",
    "    cv2.VideoWriter_fourcc(*'MJPG'),\n",
    "    fps,\n",
    "    (frame_width, frame_height)\n",
    ")\n",
    "\n",
    "while cap.isOpened():\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Resizing for faster detection\n",
    "    frame = cv2.resize(frame, (640, 480))\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Adjust HOG parameters for better detection\n",
    "    hogParams = {\n",
    "        'winStride': (8, 8),   # Default is (8,8)\n",
    "        'padding': (16, 16),   # Default is (8,8)\n",
    "        'scale': 1.05,         # Default is 1.05\n",
    "        'hitThreshold': 0.45   # Default is 0 (adjustable, higher values reduce false positives)\n",
    "    }\n",
    "\n",
    "    # Detect people in the image\n",
    "    # Returns the bounding boxes for the detected objects\n",
    "    boxes, weights = hog.detectMultiScale(frame, **hogParams)\n",
    "\n",
    "    boxes = np.array([[x, y, x + w, y + h] for (x, y, w, h) in boxes])\n",
    "\n",
    "    for (xA, yA, xB, yB) in boxes:\n",
    "        # Display the detected boxes in the colour picture\n",
    "        cv2.rectangle(frame, (xA, yA), (xB, yB), (0, 255, 0), 2)\n",
    "\n",
    "    # Write the output video\n",
    "    out.write(frame)\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('frame', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release everything if job is finished\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mobile Net Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pathlib  # Import pathlib module for handling paths\n",
    "import os      # Import os module for file operations\n",
    "\n",
    "# Function to load a TensorFlow model\n",
    "def load_model(model_name):\n",
    "    # Get the current directory\n",
    "    current_dir = pathlib.Path().resolve()\n",
    "\n",
    "    # Define the base URL and model file name\n",
    "    base_url = 'http://download.tensorflow.org/models/object_detection/'\n",
    "    model_file = model_name + '.tar.gz'\n",
    "\n",
    "    # Get the model directory path where it will be saved or has been saved\n",
    "    model_dir = tf.keras.utils.get_file(\n",
    "        fname=model_name, \n",
    "        origin=base_url + model_file,\n",
    "        untar=True,\n",
    "        cache_subdir=current_dir)  # Save in the current directory\n",
    "\n",
    "    # Set the model directory path to include the saved_model subdirectory\n",
    "    model_dir = pathlib.Path(model_dir) / \"saved_model\"\n",
    "    return model_dir\n",
    "\n",
    "# Function to perform object detection\n",
    "def detect_objects(frame, detection_function):\n",
    "    input_tensor = tf.convert_to_tensor(frame)\n",
    "    input_tensor = input_tensor[tf.newaxis,...]\n",
    "\n",
    "    detections = detection_function(input_tensor)\n",
    "\n",
    "    return detections\n",
    "\n",
    "# Function to draw bounding boxes and labels\n",
    "def draw_boxes(frame, detections, confidence_threshold=0.5):\n",
    "    height, width, _ = frame.shape\n",
    "\n",
    "    num_detections = int(detections.pop('num_detections'))\n",
    "    detections = {key: value[0, :num_detections].numpy()\n",
    "                  for key, value in detections.items()}\n",
    "    detections['num_detections'] = num_detections\n",
    "\n",
    "    for i in range(num_detections):\n",
    "        score = detections['detection_scores'][i]\n",
    "        class_id = int(detections['detection_classes'][i])\n",
    "        bbox = detections['detection_boxes'][i]\n",
    "\n",
    "        if score < confidence_threshold or class_id != 1:\n",
    "            continue\n",
    "\n",
    "        ymin, xmin, ymax, xmax = bbox\n",
    "        xmin = int(xmin * width)\n",
    "        xmax = int(xmax * width)\n",
    "        ymin = int(ymin * height)\n",
    "        ymax = int(ymax * height)\n",
    "\n",
    "        cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)\n",
    "        cv2.putText(frame, 'Person', (xmin, ymin - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36,255,12), 2)\n",
    "\n",
    "    return frame\n",
    "\n",
    "# Main function for object detection in video\n",
    "def main():\n",
    "    # Load SSD-MobileNet model\n",
    "    model_name = 'ssd_mobilenet_v2_coco_2018_03_29'\n",
    "    model_dir = load_model(model_name)\n",
    "\n",
    "    # Check if the model directory exists\n",
    "    if not os.path.exists(model_dir):\n",
    "        raise FileNotFoundError(f\"Model directory '{model_dir}' not found. Make sure the model has been downloaded correctly.\")\n",
    "\n",
    "    # Load the detection function from the saved model\n",
    "    detection_model = tf.saved_model.load(str(model_dir))\n",
    "    detection_function = detection_model.signatures['serving_default']\n",
    "\n",
    "    # Load video\n",
    "    cap = cv2.VideoCapture(r\"Videos\\dogvid.mp4\")\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        frame = cv2.resize(frame, (640, 480))  # Resize frame as needed\n",
    "\n",
    "        # Perform object detection\n",
    "        detections = detect_objects(frame, detection_function)\n",
    "\n",
    "        # Draw bounding boxes and labels on the frame (only for persons)\n",
    "        frame_with_boxes = draw_boxes(frame.copy(), detections)\n",
    "\n",
    "        # Display the frame with detected person\n",
    "        cv2.imshow('Person Detection', frame_with_boxes)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
